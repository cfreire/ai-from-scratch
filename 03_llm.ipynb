{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39613379",
   "metadata": {},
   "source": [
    "# Train with more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87dd7194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f95d9f2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08783698",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 1\n",
    "NUM_EPOCHS = 300\n",
    "LR = 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb11151",
   "metadata": {},
   "source": [
    "## Load and preprocess article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c9bac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nasa's mars rover has discovered new evidence of ancient water on the red planet rock samples taken from the surface show signs of mineral deposits that typically form in the presence of water this discovery strengthens the theory that mars may have once supported microbial life scientists are now planning future missions to explore these areas further\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"article.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read().replace('\\n', '').replace('.', '').lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca87908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: \"'\",\n",
       " 2: 'a',\n",
       " 3: 'b',\n",
       " 4: 'c',\n",
       " 5: 'd',\n",
       " 6: 'e',\n",
       " 7: 'f',\n",
       " 8: 'g',\n",
       " 9: 'h',\n",
       " 10: 'i',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'r',\n",
       " 18: 's',\n",
       " 19: 't',\n",
       " 20: 'u',\n",
       " 21: 'v',\n",
       " 22: 'w',\n",
       " 23: 'x',\n",
       " 24: 'y'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create character mappings\n",
    "chars = sorted(list(set(text)))\n",
    "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx2char = {i: ch for ch, i in char2idx.items()}\n",
    "vocab_size = len(chars)\n",
    "idx2char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d6a03",
   "metadata": {},
   "source": [
    "## Prepare sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09aed71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = char2idx[string[c]]\n",
    "    return tensor\n",
    "\n",
    "def get_batch(seq_length=SEQ_LENGTH):\n",
    "    start_index = random.randint(0, len(text) - seq_length - 1)\n",
    "    end_index = start_index + seq_length + 1\n",
    "    chunk = text[start_index:end_index]\n",
    "    input_seq = char_tensor(chunk[:-1])\n",
    "    target_seq = char_tensor(chunk[1:])\n",
    "    return input_seq, target_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fee9d9f",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18a3f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, NUM_LAYERS, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, input_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out.reshape(out.size(0)*out.size(1), out.size(2)))\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(NUM_LAYERS, 1, self.hidden_size)\n",
    "\n",
    "# Initialize model\n",
    "model = CharRNN(vocab_size, HIDDEN_SIZE, vocab_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9275af1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd73c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 10/300, Loss: 2.0565\n",
      "Epoch 20/300, Loss: 1.6593\n",
      "Epoch 30/300, Loss: 1.4354\n",
      "Epoch 40/300, Loss: 1.3993\n",
      "Epoch 50/300, Loss: 0.5734\n",
      "Epoch 60/300, Loss: 0.3261\n",
      "Epoch 70/300, Loss: 0.3978\n",
      "Epoch 80/300, Loss: 0.1777\n",
      "Epoch 90/300, Loss: 0.1346\n",
      "Epoch 100/300, Loss: 0.1430\n",
      "Epoch 110/300, Loss: 0.2036\n",
      "Epoch 120/300, Loss: 0.1271\n",
      "Epoch 130/300, Loss: 0.1130\n",
      "Epoch 140/300, Loss: 0.2805\n",
      "Epoch 150/300, Loss: 0.1502\n",
      "Epoch 160/300, Loss: 0.1120\n",
      "Epoch 170/300, Loss: 0.0662\n",
      "Epoch 180/300, Loss: 0.0927\n",
      "Epoch 190/300, Loss: 0.0892\n",
      "Epoch 200/300, Loss: 0.1328\n",
      "Epoch 210/300, Loss: 0.0313\n",
      "Epoch 220/300, Loss: 0.1361\n",
      "Epoch 230/300, Loss: 0.1864\n",
      "Epoch 240/300, Loss: 0.0641\n",
      "Epoch 250/300, Loss: 0.0749\n",
      "Epoch 260/300, Loss: 0.0221\n",
      "Epoch 270/300, Loss: 0.0800\n",
      "Epoch 280/300, Loss: 0.0443\n",
      "Epoch 290/300, Loss: 0.0912\n",
      "Epoch 300/300, Loss: 0.0951\n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    inputs, targets = get_batch()\n",
    "    inputs = inputs.unsqueeze(0)\n",
    "    targets = targets.view(-1)\n",
    "\n",
    "    hidden = model.init_hidden()\n",
    "    optimizer.zero_grad()\n",
    "    output, hidden = model(inputs, hidden)\n",
    "    loss = loss_fn(output, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622970b",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bb4da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(prompt, max_len=72):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_seq = char_tensor(prompt.lower()).unsqueeze(0)\n",
    "        hidden = model.init_hidden()\n",
    "        output_chars = list(prompt)\n",
    "\n",
    "        for i in range(max_len):\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "            last_char_logits = output[-1]\n",
    "            _, top_idx = torch.topk(last_char_logits, 1)\n",
    "            predicted_char = idx2char[top_idx.item()]\n",
    "            output_chars.append(predicted_char)\n",
    "            input_seq = char_tensor(predicted_char).unsqueeze(0)\n",
    "\n",
    "        return ''.join(output_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eb9ae3",
   "metadata": {},
   "source": [
    "## Ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4360565b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What did the Mars rover find the theory that mars may have once supported microbial life scientists \n"
     ]
    }
   ],
   "source": [
    "question = 'What did the Mars rover find'\n",
    "answer = generate_answer(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07fdb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are scientists planning future missions to explore these areas furm mnce of water this discovery streng\n"
     ]
    }
   ],
   "source": [
    "question = 'What are scientists planning'\n",
    "answer = generate_answer(question)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
